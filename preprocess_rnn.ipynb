{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification\n",
    "\n",
    "## Data Pre-Processing for Recurrent NN\n",
    "\n",
    "Fabrizio Niro - Jacopo Signò\n",
    "\n",
    "GTZAN Dataset - Music Genre Classification \n",
    "\n",
    "https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython.display as ipyd\n",
    "from collections import Counter\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import torch\n",
    "import sklearn\n",
    "import torch.nn.functional as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function \"tracksplit\" splits the audio track, loaded into an array, in n subtracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracksplit(track, nsplit = 10):\n",
    "    #splits a track in n subtracks of equal length\n",
    "    length = len(track) // nsplit\n",
    "    subtracks = []\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(nsplit):\n",
    "        subtracks.append(track[acc:acc+length])\n",
    "        acc += length\n",
    "\n",
    "    return subtracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate through the dataset structure to split all the audio tracks into 10 tracks of 3 seconds length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec3_subtracks = []\n",
    "\n",
    "for directory in os.listdir('Data/genres_original'):\n",
    "\n",
    "    for file in os.listdir('Data/genres_original/{}'.format(directory)):\n",
    "\n",
    "        try:\n",
    "            track, _ = lr.load('Data/genres_original/{}/{}'.format(directory, file))\n",
    "\n",
    "        except:\n",
    "            track, _ = lr.load('Data/genres_original/{}/{}{}'.format(directory, file[:-5], '0.wav'))\n",
    "\n",
    "        for subtr in tracksplit(track):\n",
    "\n",
    "            sec3_subtracks.append(subtr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([66179, 66924, 66150, 66176, 67580, 66770, 66000, 66968, 66140, 66440, 66814, 66528, 66167, 67228, 66308, 67012, 66134, 66352, 66946, 66792, 67034, 66616, 66418, 66506, 66682, 66198, 67210, 66748, 66594, 66880, 66110, 66374, 66330])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec3_len =[]\n",
    "for i in sec3_subtracks:\n",
    "    sec3_len.append(len(i))\n",
    "\n",
    "Counter(sec3_len).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_len = min(Counter(sec3_len).keys())\n",
    "min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([66000])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec3_subtr_trim = []\n",
    "for i in sec3_subtracks:\n",
    "    sec3_subtr_trim.append(i[:min_len])\n",
    "\n",
    "sec3_len_trim =[]\n",
    "for i in sec3_subtr_trim:\n",
    "    sec3_len_trim.append(len(i))\n",
    "\n",
    "Counter(sec3_len_trim).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('Processed_data/RNN').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/sec3_subtr_trim', 'wb') as f:\n",
    "    pickle.dump(sec3_subtracks, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas dataframe \"data\" stores for each row the track id, the label and the array of the splitted tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec3_track_id = []\n",
    "label = []\n",
    "\n",
    "for dir in os.listdir('Data/genres_original'):\n",
    "\n",
    "    for i in range(1000):\n",
    "\n",
    "        sec3_track_id.append(f'{dir}_{i}')\n",
    "        label.append(f'{dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['sec3_track_id'] = sec3_track_id\n",
    "data['label'] = label\n",
    "data['sec3_subtracks'] = sec3_subtr_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/data_id_lab_subt', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/data_id_lab_subt', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec3_track_id</th>\n",
       "      <th>label</th>\n",
       "      <th>sec3_subtracks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hiphop_0</td>\n",
       "      <td>hiphop</td>\n",
       "      <td>[-0.14361572, -0.13696289, -0.14282227, -0.153...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiphop_1</td>\n",
       "      <td>hiphop</td>\n",
       "      <td>[-0.021484375, -0.03277588, -0.059570312, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hiphop_2</td>\n",
       "      <td>hiphop</td>\n",
       "      <td>[-0.18191528, -0.046417236, -0.0680542, -0.227...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hiphop_3</td>\n",
       "      <td>hiphop</td>\n",
       "      <td>[0.016571045, 0.037506104, 0.05117798, 0.03680...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hiphop_4</td>\n",
       "      <td>hiphop</td>\n",
       "      <td>[-0.12823486, -0.1592102, -0.18588257, -0.1886...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>country_995</td>\n",
       "      <td>country</td>\n",
       "      <td>[-0.04550171, -0.15084839, -0.2517395, -0.2762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>country_996</td>\n",
       "      <td>country</td>\n",
       "      <td>[0.07611084, 0.07437134, 0.06213379, 0.0467529...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>country_997</td>\n",
       "      <td>country</td>\n",
       "      <td>[-0.120269775, -0.13812256, -0.07296753, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>country_998</td>\n",
       "      <td>country</td>\n",
       "      <td>[-0.043762207, -0.024261475, -0.033416748, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>country_999</td>\n",
       "      <td>country</td>\n",
       "      <td>[-0.025848389, -0.031677246, 0.048553467, 0.18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sec3_track_id    label                                     sec3_subtracks\n",
       "0         hiphop_0   hiphop  [-0.14361572, -0.13696289, -0.14282227, -0.153...\n",
       "1         hiphop_1   hiphop  [-0.021484375, -0.03277588, -0.059570312, -0.0...\n",
       "2         hiphop_2   hiphop  [-0.18191528, -0.046417236, -0.0680542, -0.227...\n",
       "3         hiphop_3   hiphop  [0.016571045, 0.037506104, 0.05117798, 0.03680...\n",
       "4         hiphop_4   hiphop  [-0.12823486, -0.1592102, -0.18588257, -0.1886...\n",
       "...            ...      ...                                                ...\n",
       "9995   country_995  country  [-0.04550171, -0.15084839, -0.2517395, -0.2762...\n",
       "9996   country_996  country  [0.07611084, 0.07437134, 0.06213379, 0.0467529...\n",
       "9997   country_997  country  [-0.120269775, -0.13812256, -0.07296753, -0.06...\n",
       "9998   country_998  country  [-0.043762207, -0.024261475, -0.033416748, -0....\n",
       "9999   country_999  country  [-0.025848389, -0.031677246, 0.048553467, 0.18...\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the Mel Frequency C Coef. for each splitted track. It will be the feature to feed the network with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec3_mfcc = []\n",
    "\n",
    "for i in range(len(data['sec3_subtracks'])):\n",
    "    \n",
    "    sec3_mfcc.append(lr.feature.mfcc(y=data['sec3_subtracks'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/sec3_mfcc', 'wb') as f: \n",
    "    pickle.dump(sec3_mfcc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/sec3_mfcc', 'rb') as f:\n",
    "    sec3_mfcc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the MFCC matrices of all the splitted tracks into a torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec3_mfcc = np.array(sec3_mfcc, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec3_mfcc = torch.tensor(sec3_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the target array encoding the labels with One Hot method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(data['label'])\n",
    "le = preprocessing.LabelEncoder()\n",
    "target = le.fit_transform(labels)\n",
    "target = torch.tensor(target)\n",
    "#target_one_hot = tf.one_hot(target.to(torch.int64), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4,  ..., 2, 2, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/RNN/target', 'wb') as f: \n",
    "    pickle.dump(target, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/RNN/target', 'rb') as f:\n",
    "    target = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.flatten(sec3_mfcc, start_dim=1)\n",
    "\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-208.5672, -218.5552, -192.0441,  ...,   -2.1380,   -5.1627,\n",
       "           -7.3314],\n",
       "        [-127.1170,  -86.5377,  -65.2389,  ...,  -14.1653,   -5.3262,\n",
       "           -0.6355],\n",
       "        [-112.1303, -108.4033, -131.5106,  ...,   -9.1636,   -8.7821,\n",
       "           -6.4954],\n",
       "        ...,\n",
       "        [ -98.2837,  -78.3940,  -77.5690,  ...,   -5.3651,   -3.2890,\n",
       "           -0.2495],\n",
       "        [ -93.2953,  -91.5130, -120.2912,  ...,  -18.1641,  -15.9425,\n",
       "          -10.4376],\n",
       "        [ -50.1972,  -28.8588,  -39.3822,  ...,  -11.4541,  -11.4391,\n",
       "          -10.4392]], dtype=torch.float64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4,  ..., 2, 2, 2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47011889, -0.6995086 , -0.38556404, ..., -0.12976658,\n",
       "        -0.44513298, -0.72378191],\n",
       "       [ 0.29348556,  0.46384707,  0.67899055, ..., -1.44323478,\n",
       "        -0.46296635,  0.08377488],\n",
       "       [ 0.43398751,  0.27116436,  0.12262683, ..., -0.89701777,\n",
       "        -0.83991837, -0.6229539 ],\n",
       "       ...,\n",
       "       [ 0.5638002 ,  0.53561027,  0.57547685, ..., -0.48219117,\n",
       "        -0.24076121,  0.13032775],\n",
       "       [ 0.61056695,  0.42000365,  0.21681596, ..., -1.87992993,\n",
       "        -1.62093248, -1.09839215],\n",
       "       [ 1.01461699,  0.97212047,  0.896063  , ..., -1.14715433,\n",
       "        -1.12972811, -1.09858412]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6700, 2580) torch.Size([6700])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3300, 2580) torch.Size([3300])\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/RNN/X_train', 'wb') as f: \n",
    "    pickle.dump(X_train, f)\n",
    "\n",
    "with open('Processed_data/RNN/y_train', 'wb') as f: \n",
    "    pickle.dump(y_train, f)\n",
    "\n",
    "with open('Processed_data/RNN/X_test', 'wb') as f: \n",
    "    pickle.dump(X_test, f)\n",
    "\n",
    "with open('Processed_data/RNN/y_test', 'wb') as f: \n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "523c4cb198bbdb78e31908c9a0d4ed4d5c9de132346c47b660e06a58fdf5e494"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
