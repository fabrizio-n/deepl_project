{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification\n",
    "\n",
    "## Data Pre-Processing for Recurrent NN\n",
    "\n",
    "Fabrizio Niro - Jacopo Signò\n",
    "\n",
    "GTZAN Dataset - Music Genre Classification \n",
    "\n",
    "https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython.display as ipyd\n",
    "from collections import Counter\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import torch\n",
    "import sklearn\n",
    "import torch.nn.functional as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function \"tracksplit\" splits the audio track, loaded into an array, in n subtracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracksplit(track, nsplit = 10):\n",
    "    #splits a track in n subtracks of equal length\n",
    "    length = len(track) // nsplit\n",
    "    subtracks = []\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(nsplit):\n",
    "        subtracks.append(track[acc:acc+length])\n",
    "        acc += length\n",
    "\n",
    "    return subtracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate through the dataset structure to split all the audio tracks into 10 tracks of 3 seconds length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabri\\miniconda3\\envs\\d2l\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sec3_subtracks = []\n",
    "\n",
    "for directory in os.listdir('Data/genres_original'):\n",
    "\n",
    "    for file in os.listdir('Data/genres_original/{}'.format(directory)):\n",
    "\n",
    "        try:\n",
    "            track, _ = lr.load('Data/genres_original/{}/{}'.format(directory, file))\n",
    "\n",
    "        except:\n",
    "            track, _ = lr.load('Data/genres_original/{}/{}{}'.format(directory, file[:-5], '0.wav'))\n",
    "\n",
    "        for subtr in tracksplit(track):\n",
    "\n",
    "            sec3_subtracks.append(subtr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of the arrays generated starting from the .wav files differs slightly among the set. We regularize the lengths taking as proxy the minimum length found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([66179, 66968, 66167, 66528, 66176, 66352, 66140, 66134, 67012, 67228, 66308, 66330, 66682, 66880, 66110, 66374, 66418, 66616, 66814, 66792, 66506, 66150, 66440, 66924, 66000, 66770, 67580, 66594, 67210, 66198, 66748, 67034, 66946])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec3_len =[]\n",
    "for i in sec3_subtracks:\n",
    "    sec3_len.append(len(i))\n",
    "\n",
    "Counter(sec3_len).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_len = min(Counter(sec3_len).keys())\n",
    "min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([66000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec3_subtr_trim = []\n",
    "for i in sec3_subtracks:\n",
    "    sec3_subtr_trim.append(i[:min_len])\n",
    "\n",
    "sec3_len_trim =[]\n",
    "for i in sec3_subtr_trim:\n",
    "    sec3_len_trim.append(len(i))\n",
    "\n",
    "Counter(sec3_len_trim).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('Processed_data/RNN').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/sec3_subtr_trim', 'wb') as f:\n",
    "    pickle.dump(sec3_subtracks, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas dataframe \"data\" stores for each row the track id, the label and the array of the splitted tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec3_track_id = []\n",
    "label = []\n",
    "\n",
    "for dir in os.listdir('Data/genres_original'):\n",
    "\n",
    "    for i in range(1000):\n",
    "\n",
    "        sec3_track_id.append(f'{dir}_{i}')\n",
    "        label.append(f'{dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['sec3_track_id'] = sec3_track_id\n",
    "data['label'] = label\n",
    "data['sec3_subtracks'] = sec3_subtr_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/data_id_lab_subt', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/data_id_lab_subt', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec3_track_id</th>\n",
       "      <th>label</th>\n",
       "      <th>sec3_subtracks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues_0</td>\n",
       "      <td>blues</td>\n",
       "      <td>[0.0073242188, 0.016601562, 0.0076293945, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues_1</td>\n",
       "      <td>blues</td>\n",
       "      <td>[-0.072753906, -0.055389404, -0.036102295, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues_2</td>\n",
       "      <td>blues</td>\n",
       "      <td>[0.06997681, 0.14709473, 0.2263794, 0.28271484...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues_3</td>\n",
       "      <td>blues</td>\n",
       "      <td>[-0.31854248, -0.2897339, -0.25097656, -0.2348...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues_4</td>\n",
       "      <td>blues</td>\n",
       "      <td>[0.19113159, 0.12878418, 0.06561279, -0.004669...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>rock_995</td>\n",
       "      <td>rock</td>\n",
       "      <td>[-0.004211426, 0.013061523, 0.007232666, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>rock_996</td>\n",
       "      <td>rock</td>\n",
       "      <td>[0.007659912, 0.0037231445, 0.004058838, 0.010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>rock_997</td>\n",
       "      <td>rock</td>\n",
       "      <td>[0.028564453, 0.03237915, 0.042114258, 0.05493...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>rock_998</td>\n",
       "      <td>rock</td>\n",
       "      <td>[-0.08312988, -0.07098389, -0.029724121, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>rock_999</td>\n",
       "      <td>rock</td>\n",
       "      <td>[0.014709473, 0.021728516, 0.021942139, 0.0204...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sec3_track_id  label                                     sec3_subtracks\n",
       "0          blues_0  blues  [0.0073242188, 0.016601562, 0.0076293945, -0.0...\n",
       "1          blues_1  blues  [-0.072753906, -0.055389404, -0.036102295, -0....\n",
       "2          blues_2  blues  [0.06997681, 0.14709473, 0.2263794, 0.28271484...\n",
       "3          blues_3  blues  [-0.31854248, -0.2897339, -0.25097656, -0.2348...\n",
       "4          blues_4  blues  [0.19113159, 0.12878418, 0.06561279, -0.004669...\n",
       "...            ...    ...                                                ...\n",
       "9995      rock_995   rock  [-0.004211426, 0.013061523, 0.007232666, -0.00...\n",
       "9996      rock_996   rock  [0.007659912, 0.0037231445, 0.004058838, 0.010...\n",
       "9997      rock_997   rock  [0.028564453, 0.03237915, 0.042114258, 0.05493...\n",
       "9998      rock_998   rock  [-0.08312988, -0.07098389, -0.029724121, -0.01...\n",
       "9999      rock_999   rock  [0.014709473, 0.021728516, 0.021942139, 0.0204...\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the Mel Frequency C Coef. for each splitted track. It will be the feature to feed the network with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec3_mfcc = []\n",
    "\n",
    "for i in range(len(data['sec3_subtracks'])):\n",
    "    \n",
    "    sec3_mfcc.append(lr.feature.mfcc(y=data['sec3_subtracks'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/sec3_mfcc', 'wb') as f: \n",
    "    pickle.dump(sec3_mfcc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/sec3_mfcc', 'rb') as f:\n",
    "    sec3_mfcc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the MFCC matrices of all the splitted tracks into a torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec3_mfcc = np.array(sec3_mfcc, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec3_mfcc = torch.tensor(sec3_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the target array encoding the labels with One Hot method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(data['label'])\n",
    "le = preprocessing.LabelEncoder()\n",
    "target = le.fit_transform(labels)\n",
    "target = torch.tensor(target)\n",
    "#target_one_hot = tf.one_hot(target.to(torch.int64), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 9, 9, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.flatten(sec3_mfcc, start_dim=1)\n",
    "\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4244e+02, -2.1299e+02, -1.9541e+02,  ...,  2.2183e+00,\n",
       "          8.2816e+00,  8.8715e+00],\n",
       "        [-1.6625e+02, -1.5054e+02, -1.6450e+02,  ...,  6.3761e-02,\n",
       "          2.9251e+00,  1.2711e+01],\n",
       "        [-1.3069e+02, -1.2486e+02, -1.5329e+02,  ...,  6.7889e+00,\n",
       "          6.1143e+00,  1.3908e-01],\n",
       "        ...,\n",
       "        [-2.7123e+02, -2.6610e+02, -2.7025e+02,  ...,  4.8574e-01,\n",
       "         -2.0561e+00, -4.5958e+00],\n",
       "        [-1.1438e+02, -9.3377e+01, -1.0054e+02,  ..., -3.8260e+00,\n",
       "         -2.2336e+00, -1.5710e+00],\n",
       "        [-2.6820e+02, -2.5146e+02, -2.5395e+02,  ..., -2.1837e+00,\n",
       "         -4.0726e+00, -5.3789e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 9, 9, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.78764284, -0.65046513, -0.41381591, ...,  0.34597108,\n",
       "         1.02128406,  1.23036079],\n",
       "       [-0.07341539, -0.1001311 , -0.15433941, ...,  0.11068252,\n",
       "         0.43703148,  1.69340506],\n",
       "       [ 0.2600198 ,  0.12611122, -0.06023841, ...,  0.84511728,\n",
       "         0.78488638,  0.17719336],\n",
       "       ...,\n",
       "       [-1.05758505, -1.11845248, -1.04208863, ...,  0.15676552,\n",
       "        -0.106284  , -0.39384866],\n",
       "       [ 0.41285305,  0.40357573,  0.38266885, ..., -0.31410316,\n",
       "        -0.12564417, -0.02905444],\n",
       "       [-1.02921939, -0.98946415, -0.90524509, ..., -0.13476045,\n",
       "        -0.32624082, -0.48829588]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6700, 2580) torch.Size([6700])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3300, 2580) torch.Size([3300])\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/RNN/X_train', 'wb') as f: \n",
    "    pickle.dump(X_train, f)\n",
    "\n",
    "with open('Processed_data/RNN/y_train', 'wb') as f: \n",
    "    pickle.dump(y_train, f)\n",
    "\n",
    "with open('Processed_data/RNN/X_test', 'wb') as f: \n",
    "    pickle.dump(X_test, f)\n",
    "\n",
    "with open('Processed_data/RNN/y_test', 'wb') as f: \n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6cf598af832248cfe9b39042f92a2374bbc30c7205b5dfb8694e1033392472b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
