{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification\n",
    "\n",
    "## Recurrent Neural Network Implementation\n",
    "\n",
    "Fabrizio Niro - Jacopo Sign√≤\n",
    "\n",
    "GTZAN Dataset - Music Genre Classification \n",
    "\n",
    "https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchinfo import summary\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from d2l import torch as d2l\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Processed_data/RNN/data_train', 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "\n",
    "with open('Processed_data/RNN/data_test', 'rb') as f:\n",
    "    data_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 2\n"
     ]
    }
   ],
   "source": [
    "print(len(data_train), len(data_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2\n"
     ]
    }
   ],
   "source": [
    "print(len(data_test), len(data_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_iter = data.DataLoader(data_train, batch_size, shuffle=True,\n",
    "                             num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f2727db2df0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-3.8980e+00, -3.7337e+00, -3.7626e+00,  ..., -2.1406e+00,\n",
       "           -7.5624e-01, -2.8286e+00],\n",
       "          [ 1.6081e+00,  1.7513e+00,  1.6185e+00,  ...,  3.2593e+00,\n",
       "            3.5006e+00,  2.7701e+00],\n",
       "          [ 4.9556e-01,  1.7857e-01, -3.4299e-02,  ...,  5.3055e-02,\n",
       "            4.4444e-01,  1.0718e+00],\n",
       "          ...,\n",
       "          [ 5.5450e-01,  7.4449e-01,  7.7473e-01,  ..., -1.9278e-01,\n",
       "           -3.4208e-01,  1.9200e-02],\n",
       "          [ 1.5422e-01,  2.2074e-01,  2.5529e-01,  ..., -2.1722e-01,\n",
       "           -6.8007e-01, -3.9191e-01],\n",
       "          [ 7.4397e-01,  9.6589e-01,  9.7954e-01,  ...,  5.3046e-03,\n",
       "           -4.7308e-01, -5.3522e-01]],\n",
       " \n",
       "         [[-3.9725e+00, -3.9383e+00, -4.0158e+00,  ..., -2.2626e+00,\n",
       "           -3.2860e+00, -3.7031e+00],\n",
       "          [ 1.9031e+00,  1.9770e+00,  1.8553e+00,  ...,  3.1578e+00,\n",
       "            2.7284e+00,  2.3419e+00],\n",
       "          [-2.7974e-01, -2.7592e-01, -8.3819e-02,  ..., -9.7017e-01,\n",
       "           -4.3939e-01, -2.0896e-01],\n",
       "          ...,\n",
       "          [ 1.0490e-01,  1.1696e-01,  1.0269e-01,  ..., -2.1102e-01,\n",
       "           -5.4530e-02, -4.5494e-03],\n",
       "          [-1.0711e-01, -4.5586e-02,  2.0704e-02,  ...,  3.6925e-02,\n",
       "            5.3286e-02,  5.6131e-02],\n",
       "          [-3.9471e-02, -5.9023e-02,  3.5938e-02,  ..., -1.7579e-01,\n",
       "           -1.5174e-01,  8.4216e-03]],\n",
       " \n",
       "         [[-2.5995e+00, -2.7004e+00, -3.2800e+00,  ..., -4.0077e+00,\n",
       "           -4.0553e+00, -4.0671e+00],\n",
       "          [ 3.0342e+00,  2.9271e+00,  2.4214e+00,  ...,  1.5478e+00,\n",
       "            1.4200e+00,  1.5489e+00],\n",
       "          [-8.5607e-01, -9.8237e-01, -8.5001e-01,  ..., -1.5151e-01,\n",
       "           -2.3619e-01,  1.3211e-02],\n",
       "          ...,\n",
       "          [ 2.3717e-02, -1.3657e-01, -1.3620e-01,  ..., -1.3522e-01,\n",
       "           -1.1504e-01, -6.5534e-02],\n",
       "          [-5.6130e-02, -8.6027e-02, -5.5669e-02,  ..., -5.7427e-02,\n",
       "           -4.7471e-02, -2.5898e-02],\n",
       "          [-3.4670e-01, -3.1021e-01, -4.8890e-02,  ..., -1.5626e-01,\n",
       "           -8.1601e-02, -4.3911e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-2.6843e+00, -9.5822e-01,  8.9996e-01,  ..., -1.1886e+00,\n",
       "            7.6161e-01,  9.7765e-01],\n",
       "          [ 2.4793e+00,  3.6213e+00,  3.7467e+00,  ...,  3.6517e+00,\n",
       "            3.4232e+00,  3.6082e+00],\n",
       "          [-2.4016e-01, -4.9364e-01, -2.0810e-01,  ..., -7.9836e-01,\n",
       "           -2.7761e-01,  7.8453e-02],\n",
       "          ...,\n",
       "          [ 1.4860e-01, -1.2149e-01, -5.5529e-01,  ..., -8.8749e-01,\n",
       "           -1.1200e+00, -1.2287e+00],\n",
       "          [-1.0663e+00, -1.1219e+00, -8.0673e-01,  ..., -3.7553e-01,\n",
       "           -6.9498e-01, -9.9051e-01],\n",
       "          [-2.6291e-01, -2.0988e-01, -1.5080e-01,  ..., -2.3019e-01,\n",
       "           -6.2291e-01, -4.0606e-01]],\n",
       " \n",
       "         [[-3.5277e+00, -3.6106e+00, -3.6767e+00,  ..., -3.6041e+00,\n",
       "           -3.6036e+00, -3.6930e+00],\n",
       "          [ 2.6120e+00,  2.4543e+00,  2.2273e+00,  ...,  2.4164e+00,\n",
       "            2.4265e+00,  2.3595e+00],\n",
       "          [ 2.5414e-01,  2.3846e-01,  1.2877e-01,  ..., -5.8498e-01,\n",
       "           -5.1084e-01, -3.8270e-01],\n",
       "          ...,\n",
       "          [-8.1517e-02,  5.2205e-02,  2.3524e-01,  ...,  1.1245e-02,\n",
       "           -2.2219e-02,  8.4864e-02],\n",
       "          [-9.3921e-02, -1.4326e-01, -1.6782e-01,  ...,  3.5545e-02,\n",
       "            5.2574e-02,  8.7869e-02],\n",
       "          [-8.1220e-02, -1.6757e-01, -2.9834e-01,  ...,  3.7194e-02,\n",
       "            9.4360e-02,  3.8209e-02]],\n",
       " \n",
       "         [[-2.9264e+00, -2.7755e+00, -3.0006e+00,  ..., -3.2427e+00,\n",
       "           -3.2583e+00, -3.0376e+00],\n",
       "          [ 3.1827e+00,  3.3420e+00,  3.1866e+00,  ...,  2.9230e+00,\n",
       "            2.9075e+00,  3.0244e+00],\n",
       "          [-1.0481e-01, -3.5669e-01, -4.2014e-01,  ..., -2.6447e-01,\n",
       "           -3.1060e-01, -4.0973e-01],\n",
       "          ...,\n",
       "          [-3.1544e-02,  1.7889e-02,  2.0325e-02,  ..., -8.6312e-04,\n",
       "            7.5951e-02,  2.6373e-02],\n",
       "          [-1.5562e-01, -1.2142e-01, -4.7472e-02,  ..., -3.5303e-02,\n",
       "            3.6223e-03,  1.3097e-01],\n",
       "          [-1.3110e-01, -2.2455e-01, -2.1612e-01,  ..., -1.2325e-01,\n",
       "           -1.1520e-01, -1.5073e-01]]]),\n",
       " tensor([8, 0, 8, 8, 9, 1, 4, 2, 9, 3, 3, 3, 3, 5, 4, 9, 8, 4, 9, 2, 8, 8, 7, 9,\n",
       "         9, 5, 8, 9, 5, 9, 5, 8, 1, 0, 2, 4, 7, 5, 6, 4, 8, 9, 8, 0, 1, 7, 6, 3,\n",
       "         7, 3, 4, 7, 8, 2, 4, 0, 1, 9, 8, 0, 5, 3, 8, 0])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = data.DataLoader(data_test, batch_size, shuffle=False,\n",
    "                             num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f272cdbec10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 129])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_iter))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 129])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_iter))[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2580"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = data_train[0][0].shape[0] * data_train[0][0].shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_num = 10\n",
    "classes_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelRNN, self).__init__()\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        self.rnn = nn.LSTM(input_dim, input_dim)\n",
    "        \n",
    "        self.body = nn.Sequential(\n",
    "          nn.Linear(input_dim, 1000),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(1000, 200),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(200, classes_num),\n",
    "          nn.Softmax()\n",
    "          ) \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.flat(x)\n",
    "        x, _ = self.rnn(x) # <- ignore second output\n",
    "        x = self.body(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ModelRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m): # argument m shall be a layer\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weights); # apply() will call init_weights() providing it with each layer of net as actual argument m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, train_iter, loss, updater):\n",
    "    \"\"\"The training loop\"\"\"\n",
    "    # Set the model to training mode\n",
    "\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # Sum of training loss, sum of training accuracy, nb. of examples\n",
    "    metric = d2l.Accumulator(3)\n",
    "\n",
    "    for X, y in train_iter:\n",
    "\n",
    "        # Compute gradients and update parameters\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        updater.zero_grad()\n",
    "        l.backward()\n",
    "        updater.step()\n",
    "        metric.add(float(l) * len(y), d2l.accuracy(y_hat, y), y.size().numel())\n",
    "        \n",
    "    # Return training loss and training accuracy\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, loss, num_epochs, updater):\n",
    "    \"\"\"Train a model\"\"\"\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "                        legend=['train loss', 'train acc', 'test acc'])\n",
    "                        \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_metrics = train_epoch(net, train_iter, loss, updater)\n",
    "        # ! WARNING !: d2l.evaluate_accuracy() no longer defined. Use d2l.evaluate_accuracy_gpu() instead\n",
    "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "\n",
    "    train_loss, train_acc = train_metrics\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "train_loss, train_acc = train(net, train_iter, test_iter, loss, num_epochs, trainer)\n",
    "print(\"Loss: \", train_loss)\n",
    "print(\"Accuracy: \", train_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d790fb20b6fae2e1b6718372c6237e86c2aea3e82a0d3ea3895ed3571041fb36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
